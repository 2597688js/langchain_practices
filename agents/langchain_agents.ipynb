{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1f3117-bb8b-472d-aa81-e6bdfc2f0a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394bc17e-7694-40bd-9935-4dc4497a04b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017271aa-800f-44b3-880c-eb907dbe84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1721930974, 'localtime': '2024-07-25 11:09'}, 'current': {'last_updated_epoch': 1721930400, 'last_updated': '2024-07-25 11:00', 'temp_c': 18.5, 'temp_f': 65.3, 'is_day': 1, 'condition': {'text': 'Patchy rain nearby', 'icon': '//cdn.weatherapi.com/weather/64x64/day/176.png', 'code': 1063}, 'wind_mph': 7.2, 'wind_kph': 11.5, 'wind_degree': 245, 'wind_dir': 'WSW', 'pressure_mb': 1018.0, 'pressure_in': 30.07, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 65, 'cloud': 72, 'feelslike_c': 18.5, 'feelslike_f': 65.3, 'windchill_c': 18.5, 'windchill_f': 65.3, 'heatindex_c': 18.5, 'heatindex_f': 65.3, 'dewpoint_c': 11.9, 'dewpoint_f': 53.4, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 4.0, 'gust_mph': 9.5, 'gust_kph': 15.3}}\"}, {'url': 'https://www.wunderground.com/hourly/us/ca/san-francisco/94177/date/2024-07-25', 'content': 'San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area. ... Thursday 07/ ...'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a651c884-0fbf-4c0e-a94f-524c340388e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72ff479-5880-4319-9d67-5b30883651e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08da48d-d39e-4e16-8e96-f72aa3fa5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d830f5-b027-4dc9-b8f6-7cd2f4e56974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e55928-944f-49b0-9777-839c89fc10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_GKKWZG91Q3CUgsHNXPiaHxZz', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7984dd4d-ba28-4b68-92ce-a2e6ab023c75",
   "metadata": {},
   "source": [
    "We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "\n",
    "This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f73fcc-9bf7-4144-9a46-da486200ede4",
   "metadata": {},
   "source": [
    "## Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0af0cb1-2b85-4684-b7d5-3eb05b5e4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc37670f-75f2-424d-897b-4f7a89945da3",
   "metadata": {},
   "source": [
    "Note that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51398f1f-f939-4298-8aeb-e3c081d06a77",
   "metadata": {},
   "source": [
    "## Run the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809f42f-acba-48a5-aab3-32d096fbfc18",
   "metadata": {},
   "source": [
    "### let's see how it responds when there's no need to call a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f045bd4-d580-42f0-9fb8-1d11883dcfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', id='4b64b419-349f-44a8-aba5-9079d3dc1360'),\n",
       " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 83, 'total_tokens': 93}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-573bc61e-3507-483b-9956-5382fcce8596-0', usage_metadata={'input_tokens': 83, 'output_tokens': 10, 'total_tokens': 93})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f727e-60fa-4589-acc7-9d4020a760a3",
   "metadata": {},
   "source": [
    "### Let's now try it out on an example where it should be invoking the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab4ddcf2-0d94-4e82-ab4e-5d566a401150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in sf?', id='31a1bcbf-ad08-4909-a443-08e97c487141'),\n",
       " AIMessage(content='I\\'m sorry for the inconvenience. As an AI model developed by OpenAI, I currently don\\'t have the capability to provide real-time information or updates such as weather forecasts. However, you can easily find the current weather in San Francisco by searching for \"San Francisco weather\" on any reliable weather forecasting website or app such as the National Weather Service, Weather.com, or your smartphone\\'s weather app.', response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 88, 'total_tokens': 169}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0fdb27df-a579-4519-8b9d-621da55f625a-0', usage_metadata={'input_tokens': 88, 'output_tokens': 81, 'total_tokens': 169})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a36e4b-b38c-4223-b0d1-79c7bf2b67ef",
   "metadata": {},
   "source": [
    "## Streaming Messages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2eae7690-c0df-4c1e-a864-9c927dfd8272",
   "metadata": {},
   "source": [
    "We've seen how the agent can be called with .invoke to get back a final response. If the agent is executing multiple steps, that may take a while. In order to show intermediate progress, we can stream back messages as they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b840d7-e94c-4ae2-9cb4-96c190e21585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DUtYIGUEeJMaYbHTvb6YKqY8', 'function': {'arguments': '{\\n  \"query\": \"current weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 88, 'total_tokens': 111}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33d25c6b-ab66-4da8-8d8a-2cb2f019ac02-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_DUtYIGUEeJMaYbHTvb6YKqY8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 23, 'total_tokens': 111})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1721932995, \\'localtime\\': \\'2024-07-25 11:43\\'}, \\'current\\': {\\'last_updated_epoch\\': 1721932200, \\'last_updated\\': \\'2024-07-25 11:30\\', \\'temp_c\\': 18.5, \\'temp_f\\': 65.3, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Patchy rain nearby\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/176.png\\', \\'code\\': 1063}, \\'wind_mph\\': 7.2, \\'wind_kph\\': 11.5, \\'wind_degree\\': 245, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1018.0, \\'pressure_in\\': 30.07, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 72, \\'feelslike_c\\': 18.5, \\'feelslike_f\\': 65.3, \\'windchill_c\\': 18.5, \\'windchill_f\\': 65.3, \\'heatindex_c\\': 18.5, \\'heatindex_f\\': 65.3, \\'dewpoint_c\\': 11.9, \\'dewpoint_f\\': 53.4, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 4.0, \\'gust_mph\\': 9.5, \\'gust_kph\\': 15.3}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/hourly\", \"content\": \"Hour-by-Hour Forecast for San Francisco, California, USA. Currently: 55 \\\\u00b0F. Passing clouds. (Weather station: San Francisco International Airport, USA). See more current weather.\"}]', name='tavily_search_results_json', tool_call_id='call_DUtYIGUEeJMaYbHTvb6YKqY8')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"The current weather in San Francisco, California is approximately 65.3°F (18.5°C) with patchy rain nearby. The wind is coming from the WSW at about 7.2 mph (11.5 kph), and the humidity is at 65%. Please note that this information might change rapidly, so it's always a good idea to check a reliable source shortly before you go out.\", response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 601, 'total_tokens': 686}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-df6290d7-5e60-4b29-8696-f287121503de-0', usage_metadata={'input_tokens': 601, 'output_tokens': 85, 'total_tokens': 686})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04f880-1a29-40cd-bd6a-55553e239529",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1a69212-debf-445c-b1ca-9bb1c26e7efb",
   "metadata": {},
   "source": [
    "In addition to streaming back messages, it is also useful to be streaming back tokens. We can do this with the .astream_events method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8be6ff7-ac01-48dc-989e-88b4c2735080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\LangChain\\langchain_conda_env\\lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Starting tool: tavily_search_results_json with inputs: {'query': 'current weather in San Francisco'}\n",
      "Done tool: tavily_search_results_json\n",
      "Tool output was: content=[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1721933207, 'localtime': '2024-07-25 11:46'}, 'current': {'last_updated_epoch': 1721933100, 'last_updated': '2024-07-25 11:45', 'temp_c': 18.5, 'temp_f': 65.3, 'is_day': 1, 'condition': {'text': 'Patchy rain nearby', 'icon': '//cdn.weatherapi.com/weather/64x64/day/176.png', 'code': 1063}, 'wind_mph': 7.2, 'wind_kph': 11.5, 'wind_degree': 245, 'wind_dir': 'WSW', 'pressure_mb': 1018.0, 'pressure_in': 30.07, 'precip_mm': 0.01, 'precip_in': 0.0, 'humidity': 65, 'cloud': 72, 'feelslike_c': 18.5, 'feelslike_f': 65.3, 'windchill_c': 18.5, 'windchill_f': 65.3, 'heatindex_c': 18.5, 'heatindex_f': 65.3, 'dewpoint_c': 11.9, 'dewpoint_f': 53.4, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 4.0, 'gust_mph': 9.5, 'gust_kph': 15.3}}\"}, {'url': 'https://world-weather.info/forecast/usa/san_francisco/july-2024/', 'content': \"San Francisco Weather Forecast for July 2024 is based on long term prognosis and previous years' statistical data.\"}] name='tavily_search_results_json' tool_call_id='call_On5ZGVegNO03nxXOyXYNDud9'\n",
      "--\n",
      "The| current| weather| in| San| Francisco|,| California|,| USA| is| as| follows|:\n",
      "|-| Temperature|:| |18|.|5|°C| (|65|.|3|°F|)\n",
      "|-| Condition|:| Patch|y| rain| nearby|\n",
      "|-| Wind| speed|:| |7|.|2| mph| (|11|.|5| k|ph|),| direction|:| W|SW|\n",
      "|-| Pressure|:| |101|8|.|0| mb|\n",
      "|-| Hum|idity|:| |65|%\n",
      "|-| Visibility|:| |10|.|0| km| (|6|.|0| miles|)\n",
      "|-| UV| index|:| |4|.|0|\n",
      "\n",
      "|Please| note|,| weather| conditions| are| subject| to| change| rapidly|.| [|Source|](|https|://|www|.weather|api|.com|/)|"
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42467be-1dfd-40c4-bd6f-a6ba8706f25d",
   "metadata": {},
   "source": [
    "## Adding in memory"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9f73255-97c1-4d6b-ae87-78cd2760901f",
   "metadata": {},
   "source": [
    "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074a582c-5876-4215-a501-710aa68e697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0eb179-2cef-44c6-b3a3-3a6c4790e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d50e54e-508d-4235-b3c6-da696a85ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello, Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 85, 'total_tokens': 97}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d88c2d4f-90fe-40c9-bba4-4c938c76e550-0', usage_metadata={'input_tokens': 85, 'output_tokens': 12, 'total_tokens': 97})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f230ac69-2045-4071-9004-e6a1f78ffbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 109, 'total_tokens': 115}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-60be9105-991c-42b1-b9be-e741505a34e5-0', usage_metadata={'input_tokens': 109, 'output_tokens': 6, 'total_tokens': 115})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79cb97f-f545-454b-835d-dc582f737001",
   "metadata": {},
   "source": [
    "#### If I want to start a new conversation, all I have to do is change the thread_id used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ad2cda-784c-43c6-a895-b2aabc22bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"As an AI, I'm sorry but I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 86, 'total_tokens': 129}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6a683e2f-170c-4a74-8fef-1eb227adadf9-0', usage_metadata={'input_tokens': 86, 'output_tokens': 43, 'total_tokens': 129})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7649c-2ace-452d-b358-b40f454c5579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306b9ab-9a81-4a3e-896b-1d2d9cd93c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7b55f-e5e9-4743-bef1-e053b6b79842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_conda_env",
   "language": "python",
   "name": "langchain_conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
